{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30136340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15]\n",
      "âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼Œæ‰€æœ‰æ¨¡å—åŠ DataLoader å·²å°±ç»ªã€‚\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. è‡ªåŠ¨è·å–å½“å‰å·¥ä½œç›®å½•å¹¶ä¿®å¤è·¯å¾„\n",
    "root_dir = os.getcwd() \n",
    "sys.path.append(root_dir)\n",
    "\n",
    "# å¼ºåˆ¶æ˜ å°„çˆ¶ç›®å½•ä»¥è§£å†³ Data_processing.py å†…éƒ¨çš„å¯¼å…¥å†²çª\n",
    "parent_dir = os.path.dirname(root_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# 2. æ˜¾å¼å¯¼å…¥æ‰€æœ‰å¿…è¦çš„ PyTorch ç»„ä»¶\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader  # <--- ä¿®å¤ NameError çš„å…³é”®\n",
    "from torch.cuda.amp import GradScaler\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "# æ·»åŠ  functions.py æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„\n",
    "sys.path.append('/host/d/GitHub/Whole_heart_segmentation_junzhe2/functions_collection')\n",
    "import functions as ff\n",
    "\n",
    "# 3. æ¨¡å—å¯¼å…¥ä¸åŒ…åæ˜ å°„è¡¥ä¸\n",
    "try:\n",
    "    # å¼ºåˆ¶å°†å½“å‰æ–‡ä»¶å¤¹åæ˜ å°„ä¸ºæ¨¡å—åï¼Œå¤„ç† Data_processing.py é‡Œçš„æ—§è·¯å¾„\n",
    "    folder_name = os.path.basename(root_dir)\n",
    "    sys.modules['Whole_heart_segmentation_junzhe'] = __import__(folder_name)\n",
    "    \n",
    "    import functions_collection as ff\n",
    "    import Data_processing\n",
    "    from Build_lists.Build_list import Build \n",
    "    import data_loader.random_aug as randaug\n",
    "    import data_loader.generator as generator\n",
    "    import segment_anything.model as model\n",
    "    print(\"âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼Œæ‰€æœ‰æ¨¡å—åŠ DataLoader å·²å°±ç»ªã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ å¯¼å…¥æé†’: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21de6f2",
   "metadata": {},
   "source": [
    "### step 1: define trial name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de8cb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'trial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0354b4",
   "metadata": {},
   "source": [
    "### step 2: build patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac4e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ æˆåŠŸåŠ è½½ 6 ä¸ªæ ·æœ¬ï¼\n",
      "ğŸ” æ£€æŸ¥ç¬¬ä¸€æ¡å›¾ç‰‡è·¯å¾„: /host/d/GitHub/Whole_heart_segmentation_junzhe2/example_data/data/ID_0002/img/slice_0.nii.gz\n",
      "ğŸ” æ£€æŸ¥ç¬¬ä¸€æ¡æ ‡ç­¾è·¯å¾„: /host/d/GitHub/Whole_heart_segmentation_junzhe2/example_data/data/ID_0002/seg/slice_0.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# å•å…ƒæ ¼ 3ï¼šç»ˆæè·¯å¾„ä¿®å¤ (åŸºäº ID_ é”šç‚¹)\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import os\n",
    "from Build_lists.Build_list import Build \n",
    "\n",
    "# 1. é”å®šæ–°ç”µè„‘ä¸Šçš„çœŸå®æ•°æ®æ ¹ç›®å½•\n",
    "# æ ¹æ®æ‚¨æä¾›çš„è·¯å¾„ï¼š/host/d/.../example_data/data/ID_0002/img\n",
    "# æ‚¨çš„æ•°æ®å­˜æ”¾åœ¨ root_dir ä¸‹çš„ example_data/data æ–‡ä»¶å¤¹é‡Œ\n",
    "root_dir = os.getcwd() \n",
    "new_data_root = os.path.join(root_dir, 'example_data', 'data')\n",
    "\n",
    "# 2. å®šä¹‰ Excel ä½ç½®\n",
    "patient_list_spreadsheet = os.path.join(root_dir, 'example_data', 'Patient_list', 'patient_list.xlsx')\n",
    "\n",
    "def force_fix_paths(file_path, new_root):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ° Excel æ–‡ä»¶: {file_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # è·å–ç¬¬ä¸€è¡Œè·¯å¾„çœ‹çœ‹æ ·å­\n",
    "    sample_path = str(df.iloc[0, 0])\n",
    "    \n",
    "    # å¦‚æœè·¯å¾„é‡Œå·²ç»åŒ…å«äº† new_rootï¼Œè¯´æ˜æ”¹è¿‡äº†ï¼Œç›´æ¥è¿”å›\n",
    "    # æ³¨æ„ï¼šç»Ÿä¸€è½¬æˆ / æ¥æ¯”è¾ƒï¼Œé˜²æ­¢ Windows åæ–œæ å¹²æ‰°\n",
    "    if new_root.replace('\\\\', '/') in sample_path.replace('\\\\', '/'):\n",
    "        print(\"âœ… Excel è·¯å¾„å·²ç»æ˜¯æ­£ç¡®çš„ï¼Œæ— éœ€é‡å¤ä¿®æ”¹ã€‚\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ” æ£€æµ‹åˆ°æ—§è·¯å¾„æ ·æœ¬: {sample_path}\")\n",
    "    print(\"âš¡ï¸ æ­£åœ¨ä½¿ç”¨ 'ID_' ä½œä¸ºé”šç‚¹è¿›è¡Œå¼ºåˆ¶æ›¿æ¢...\")\n",
    "\n",
    "    # --- æ ¸å¿ƒä¿®å¤é€»è¾‘ ---\n",
    "    # ä¸ç®¡æ—§è·¯å¾„é•¿ä»€ä¹ˆæ ·ï¼Œåªè¦æ‰¾åˆ° \"ID_\"ï¼Œåé¢çš„éƒ¨åˆ†(ID_0002/img.nii...)ä¿ç•™\n",
    "    # å‰é¢çš„éƒ¨åˆ†å…¨éƒ¨æ›¿æ¢æˆæ–°çš„ new_root\n",
    "    def replace_rule(old_path):\n",
    "        old_path = str(old_path).replace('\\\\', '/') # ç»Ÿä¸€è½¬æˆ Linux æ–œæ \n",
    "        if 'ID_' in old_path:\n",
    "            # åˆ‡å‰²è·¯å¾„ï¼Œåªä¿ç•™ ID_ åŠå…¶åé¢çš„éƒ¨åˆ†\n",
    "            # ä¾‹å¦‚: D:/Data/ID_0002/img -> ID_0002/img\n",
    "            suffix = old_path.split('ID_')[-1] \n",
    "            # æ‹¼æ¥æ–°å‰ç¼€\n",
    "            # ç»“æœ: /host/.../example_data/data/ID_0002/img\n",
    "            return os.path.join(new_root, 'ID_' + suffix)\n",
    "        return old_path\n",
    "\n",
    "    # å¯¹æ‰€æœ‰åˆ—åº”ç”¨è¿™ä¸ªè§„åˆ™\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(replace_rule)\n",
    "\n",
    "    # ä¿å­˜\n",
    "    df.to_excel(file_path, index=False)\n",
    "    print(f\"âœ… è·¯å¾„å¼ºåˆ¶ä¿®å¤å®Œæˆï¼å·²ä¿å­˜åˆ°: {file_path}\")\n",
    "    print(f\"ğŸ†• æ–°è·¯å¾„ç¤ºä¾‹: {df.iloc[0, 0]}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. éªŒè¯åŠ è½½ (ä¿®æ”¹è¿™éƒ¨åˆ†ï¼Œç¡®ä¿å˜é‡åå¯¹åº”)\n",
    "# ==========================================\n",
    "try:\n",
    "    build_sheet = Build(patient_list_spreadsheet)\n",
    "    \n",
    "    # âš ï¸ å…³é”®ä¿®æ”¹ï¼šå¿…é¡»ç”¨è¿™ 5 ä¸ªå˜é‡æ¥ä½ç»“æœï¼Œåé¢ Cell 4 æ‰èƒ½ç”¨ï¼\n",
    "    # è¿™é‡Œçš„ img_file_list_train å’Œ seg_file_list_train å°±æ˜¯ Cell 4 è¦æ‰¾çš„ä¸œè¥¿\n",
    "    _, _, _, img_file_list_train, seg_file_list_train = build_sheet.__build__(batch_list=[0])\n",
    "\n",
    "    if len(img_file_list_train) > 0:\n",
    "        print(f\"ğŸ‰ æˆåŠŸåŠ è½½ {len(img_file_list_train)} ä¸ªæ ·æœ¬ï¼\")\n",
    "        print(f\"ğŸ” æ£€æŸ¥ç¬¬ä¸€æ¡å›¾ç‰‡è·¯å¾„: {img_file_list_train[0]}\")\n",
    "        print(f\"ğŸ” æ£€æŸ¥ç¬¬ä¸€æ¡æ ‡ç­¾è·¯å¾„: {seg_file_list_train[0]}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ åˆ—è¡¨ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ example_data/data æ–‡ä»¶å¤¹é‡Œæ˜¯å¦æœ‰ ID_xxxx æ–‡ä»¶å¤¹\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ„å»ºåˆ—è¡¨å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e644e31",
   "metadata": {},
   "source": [
    "### data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4def2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define this generator\n",
    "generator_train = generator.Dataset_CMR(\n",
    "    image_file_list = img_file_list_train,\n",
    "    \n",
    "    seg_file_list = seg_file_list_train,\n",
    "\n",
    "    image_shape = [128,128],\n",
    "    center_crop_according_to_which_class  = [1], #default: crop according to class 1 (LV)\n",
    "\n",
    "    shuffle = True,\n",
    "    image_normalization = True,\n",
    "    augment = True,\n",
    "    augment_frequency = 0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0108c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = generator_train\n",
    "dl = DataLoader(ds, batch_size = 1, shuffle = False, pin_memory = True, num_workers = 0)# cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8df27c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e0691bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def get_args_parser( vit_type = \"vit_h\", original_SAM_weights = None):\n",
    "    parser = argparse.ArgumentParser('SAM fine-tuning', add_help=True)\n",
    "\n",
    "    parser.add_argument('--resume', default = original_SAM_weights)\n",
    "\n",
    "    parser.add_argument('--img_size', default=128, type=int) \n",
    "\n",
    "    parser.add_argument('--vit_type', default=vit_type, type=str, choices=[ 'vit_b', 'vit_l', 'vit_h'],)\n",
    "    \n",
    " \n",
    "    return parser\n",
    "\n",
    "original_sam = '/host/d/Data/SAM_weights/sam_vit_b_01ec64.pth'\n",
    "\n",
    "args = get_args_parser(vit_type = \"vit_b\",original_SAM_weights = original_sam)\n",
    "args = args.parse_args([])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc21e9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸåŠ è½½åŒ¹é…çš„æƒé‡ï¼Œè·³è¿‡äº†å½¢çŠ¶ä¸ç¬¦çš„è¾“å‡ºå±‚ã€‚\n",
      "--- æ”¹é€ çŠ¶æ€æ ¸æŸ¥ ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MaskDecoder' object has no attribute 'num_mask_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m our_model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mbuild_model(args, device)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m--- æ”¹é€ çŠ¶æ€æ ¸æŸ¥ ---\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39måˆ†ç±» Token æ•°é‡: \u001b[39m\u001b[39m{\u001b[39;00mour_model\u001b[39m.\u001b[39mmask_decoder\u001b[39m.\u001b[39mnum_mask_tokens\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39m# åº”æ‰“å° 3\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMLP é¢„æµ‹å¤´æ•°é‡: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(our_model\u001b[39m.\u001b[39mmask_decoder\u001b[39m.\u001b[39moutput_hypernetworks_mlps)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39m# åº”æ‰“å° 3\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# --- å•å…ƒæ ¼ 7: éªŒè¯æ•°æ®åŠ è½½ä¸è¾“å‡ºç»´åº¦ ---\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaskDecoder' object has no attribute 'num_mask_tokens'"
     ]
    }
   ],
   "source": [
    "# --- å•å…ƒæ ¼ 6: éªŒè¯ Mask Decoder ç»“æ„ ---\n",
    "our_model = model.build_model(args, device)\n",
    "print(f\"--- æ”¹é€ çŠ¶æ€æ ¸æŸ¥ ---\")\n",
    "print(f\"åˆ†ç±» Token æ•°é‡: {our_model.mask_decoder.num_mask_tokens}\") # åº”æ‰“å° 3\n",
    "print(f\"MLP é¢„æµ‹å¤´æ•°é‡: {len(our_model.mask_decoder.output_hypernetworks_mlps)}\") # åº”æ‰“å° 3\n",
    "\n",
    "# --- å•å…ƒæ ¼ 7: éªŒè¯æ•°æ®åŠ è½½ä¸è¾“å‡ºç»´åº¦ ---\n",
    "our_model.to(device)\n",
    "for batch_data in dl:\n",
    "    # ä¿®æ­£ç»´åº¦å¹¶æ¬è¿æ•°æ®\n",
    "    batch_data[\"image\"] = batch_data[\"image\"].squeeze(0).to(device)\n",
    "    \n",
    "    # æ‰§è¡Œå‰å‘ä¼ æ’­\n",
    "    output = our_model([batch_data], multimask_output=True)\n",
    "    \n",
    "    # è·å–æ©ç ç»´åº¦\n",
    "    masks_shape = output[0]['masks'].shape\n",
    "    print(f\"--- æ¨ç†æˆåŠŸ ---\")\n",
    "    print(f\"é¢„æµ‹æ©ç ç»´åº¦: {masks_shape}\") \n",
    "    # é¢„æœŸè¾“å‡º: [3, 128, 128] -> 3 ä»£è¡¨ LV, Myo, Background\n",
    "    break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ce1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0][\"masks\"].shape  # (num_masks, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# å•å…ƒæ ¼ 9ï¼šæ¨ç†ç»“æœå¯è§†åŒ–éªŒè¯ (ä¿®å¤ RuntimeError)\n",
    "# ==========================================\n",
    "# 1. ä½¿ç”¨ .detach() å‰¥ç¦»æ¢¯åº¦\n",
    "a = output[0][\"masks\"].detach().cpu().numpy()\n",
    "\n",
    "print('--- æ¨ç†æ•°æ®ç»Ÿè®¡ ---')\n",
    "print(f'æ©ç å¼ é‡ç»´åº¦: {a.shape}') # é¢„æœŸ: [3, 128, 128]\n",
    "print(f'åƒç´ æœ€å¤§å€¼: {np.max(a):.4f}, æœ€å°å€¼: {np.min(a):.4f}')\n",
    "\n",
    "# 2. éªŒè¯ 3 åˆ†ç±»é€»è¾‘\n",
    "if a.shape[0] == 3:\n",
    "    print(\"âœ… éªŒè¯æˆåŠŸï¼šè¾“å‡ºåŒ…å« 3 ä¸ªé€šé“ï¼Œåˆ†åˆ«å¯¹åº” LVã€å¿ƒè‚Œå’ŒèƒŒæ™¯ã€‚\")\n",
    "    \n",
    "    # å¯é€‰ï¼šç®€å•æ‰“å°å„é€šé“å‡å€¼ï¼Œç¡®è®¤å„é€šé“å‡æœ‰æ¿€æ´»\n",
    "    for i, label in enumerate(['Background', 'LV Pool', 'Myocardium']):\n",
    "        print(f\"é€šé“ {i} ({label}) å‡å€¼æ¿€æ´»åº¦: {np.mean(a[i]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa676b",
   "metadata": {},
   "source": [
    "å®šä¹‰LOSSå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e967925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®ä¼˜åŒ–å™¨ \n",
    "trainable_params = filter(lambda p: p.requires_grad, our_model.parameters())\n",
    "optimizer = optim.AdamW(trainable_params, lr=1e-4, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#å®šä¹‰ Loss\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ··åˆç²¾åº¦ Scaler\n",
    "loss_scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f13715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"models/my_trial\", exist_ok=True)\n",
    "print(\"æ–‡ä»¶å¤¹åˆ›å»ºæˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29b32c",
   "metadata": {},
   "source": [
    "è¿›è¡Œè®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43538729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# å¼ºåˆ¶æ‰‹åŠ¨å®šä¹‰è½®æ•°ï¼Œä¸å†ä¾èµ–å®¹æ˜“å‡ºé”™çš„ args\n",
    "# -------------------------------------------------------------\n",
    "RUN_EPOCHS = 50   # <--- æˆ‘ä»¬ç›´æ¥åœ¨è¿™é‡Œå®šä¹‰ï¼Œä¸ç”¨ç®¡ args é‡Œå«ä»€ä¹ˆäº†\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# è®¡ç®—æ€»æ­¥æ•°\n",
    "total_steps = len(dl) * RUN_EPOCHS\n",
    "\n",
    "print(f\" å¼€å§‹è®­ç»ƒ... å…± {RUN_EPOCHS} è½®ï¼Œæ€»è®¡ {total_steps} æ­¥\")\n",
    "\n",
    "our_model.train() # åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼\n",
    "\n",
    "# åˆ›å»ºæ€»è¿›åº¦æ¡\n",
    "pbar = tqdm(total=total_steps, desc=\"æ€»ä½“è®­ç»ƒè¿›åº¦\", unit=\"step\")\n",
    "\n",
    "for epoch in range(1, RUN_EPOCHS + 1):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # å†…å±‚å¾ªç¯ç›´æ¥éå† dl\n",
    "    for step, batch_data in enumerate(dl):\n",
    "        \n",
    "        # --- (A) æ•°æ®æ¬è¿ ---\n",
    "        images = batch_data[\"image\"].cuda()\n",
    "        gt_masks = batch_data[\"mask\"].cuda().long().squeeze(1)\n",
    "        \n",
    "        batched_input = []\n",
    "        for i in range(len(images)):\n",
    "            batched_input.append({\n",
    "                'image': images[i],\n",
    "                'original_size': (args.img_size, args.img_size)\n",
    "            })\n",
    "            \n",
    "        # --- (B) å‰å‘ä¼ æ’­ ---\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = our_model(batched_input, multimask_output=True)\n",
    "            pred_masks = torch.stack([o['masks'] for o in outputs]).squeeze(1)\n",
    "            loss = criterion(pred_masks, gt_masks)\n",
    "        \n",
    "        # --- (C) åå‘ä¼ æ’­ ---\n",
    "        loss_scaler.scale(loss).backward()\n",
    "        loss_scaler.step(optimizer)\n",
    "        loss_scaler.update()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # 4. æ‰‹åŠ¨æ›´æ–°æ€»è¿›åº¦æ¡\n",
    "        pbar.update(1) \n",
    "        pbar.set_postfix({\n",
    "            'epoch': f\"{epoch}/{RUN_EPOCHS}\",\n",
    "            'loss': f\"{loss.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    # (å¯é€‰) æ‰“å°æ¯è½®å¹³å‡ Loss\n",
    "    # avg_loss = epoch_loss / len(dl)\n",
    "    # print(f\"Epoch {epoch} ç»“æŸ | Avg Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # ä¿å­˜æ¨¡å‹\n",
    "    if epoch % 5 == 0:\n",
    "        save_path = os.path.join(\"models/my_trial\", f\"model_epoch_{epoch}.pth\")\n",
    "        torch.save(our_model.state_dict(), save_path)\n",
    "\n",
    "pbar.close()\n",
    "print(\"\\n è®­ç»ƒå…¨éƒ¨å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# å•å…ƒæ ¼ 16ï¼šä¿®å¤åçš„æ¨ç†ä¸ BBox æ‰“å°\n",
    "# ==========================================\n",
    "for batch_data in dl:\n",
    "    # æå–å½“å‰çš„ Ground Truth Mask\n",
    "    gt_mask = batch_data[\"mask\"].squeeze().cpu().numpy() # å˜ä¸º (128, 128)\n",
    "    \n",
    "    # è°ƒç”¨å‡½æ•°ï¼Œpadding è®¾ä¸º 10\n",
    "    bbox_results = ff.get_tilted_3d_bbox(gt_mask, padding=10)\n",
    "    \n",
    "    if bbox_results:\n",
    "        print(f\"âœ… BBox æå–æˆåŠŸï¼š{bbox_results['sam_prompt']}\")\n",
    "        # éªŒè¯æ­£æ–¹å½¢çº¦æŸ\n",
    "        x1, y1, x2, y2 = bbox_results['sam_prompt']\n",
    "        print(f\"ğŸ“ Xè·¨åº¦: {x2-x1}, Yè·¨åº¦: {y2-y1} (åº”ç›¸ç­‰)\")\n",
    "    \n",
    "    # æ¥ä¸‹æ¥çš„æ¨¡å‹æ¨ç†é€»è¾‘...\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# å•å…ƒæ ¼ 17ï¼šä¿®å¤è®¾å¤‡å†²çªå¹¶æ‰§è¡Œæ¨ç†\n",
    "# ==========================================\n",
    "our_model.to(device) # ç¡®ä¿æ¨¡å‹åœ¨ GPU\n",
    "our_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        # --- å…³é”®ä¿®å¤ï¼šæ¬è¿æ•°æ®åˆ° GPU ---\n",
    "        input_image = batch_data[\"image\"].to(device)\n",
    "        \n",
    "        # å¤„ç† BBox æç¤ºè¯ (Task B.2)\n",
    "        gt_mask_np = batch_data[\"mask\"].squeeze().cpu().numpy()\n",
    "        bbox_res = ff.get_tilted_3d_bbox(gt_mask_np, padding=10)\n",
    "        \n",
    "        if bbox_res:\n",
    "            # åŒæ ·éœ€è¦å°† box æ¬è¿åˆ° GPU\n",
    "            box_prompt = torch.tensor(bbox_res['sam_prompt']).to(device).unsqueeze(0)\n",
    "        else:\n",
    "            box_prompt = None\n",
    "\n",
    "        # æ„é€ ç¬¦åˆ SAM æ ¼å¼çš„è¾“å…¥å­—å…¸\n",
    "        # æ³¨æ„ï¼šSAM çš„ forward æ¥æ”¶çš„æ˜¯ List[Dict]\n",
    "        single_input = {\n",
    "            'image': input_image.squeeze(0) if input_image.dim()==4 else input_image, \n",
    "            'boxes': box_prompt,\n",
    "            'original_size': (128, 128)\n",
    "        }\n",
    "\n",
    "        # æ‰§è¡Œæ¨ç†\n",
    "        output = our_model([single_input], multimask_output=True)\n",
    "        \n",
    "        # æˆåŠŸå®šä¹‰å˜é‡ï¼Œä¾›å¯è§†åŒ–ä½¿ç”¨\n",
    "        final_masks = output[0]['masks']\n",
    "\n",
    "print(f\"âœ… è®¾å¤‡å¯¹é½æˆåŠŸã€‚è¾“å‡ºç»´åº¦: {final_masks.shape} (Task B.1 éªŒè¯é€šè¿‡)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de246ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 1. ç¡®ä¿å‰¥ç¦»æ¢¯åº¦å¹¶è½¬æ¢ä¸ºæ¦‚ç‡\n",
    "# å‡è®¾ final_masks æ¥è‡ªæ¨¡å‹è¾“å‡º\n",
    "# å¦‚æœ final_masks æ˜¯ [1, 3, 128, 128]ï¼Œå…ˆ squeeze(0) å»æ‰ batch ç»´åº¦\n",
    "if final_masks.dim() == 4:\n",
    "    final_masks = final_masks.squeeze(0)\n",
    "\n",
    "probs = torch.sigmoid(final_masks).detach().cpu().numpy()\n",
    "\n",
    "# æ­¤æ—¶ probs åº”è¯¥æ˜¯ (3, 128, 128)\n",
    "print(f\"å¯è§†åŒ–æ•°æ®å½¢çŠ¶ (Probs Shape): {probs.shape}\")\n",
    "\n",
    "# 2. è·å–åº•å›¾\n",
    "img_bg = batch_data[\"image\"].squeeze().cpu().numpy()\n",
    "if img_bg.ndim == 3: # å¤„ç† [3, 1024, 1024]\n",
    "    img_bg = img_bg[0]\n",
    "\n",
    "# 3. ç»˜å›¾é…ç½®\n",
    "labels = ['Background', 'LV Pool', 'Myocardium']\n",
    "cmaps = ['gray', 'Blues', 'Greens', 'Reds']\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# ç¬¬ä¸€å¼ ï¼šåº•å›¾\n",
    "axes[0].imshow(img_bg, cmap='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# åé¢ä¸‰å¼ ï¼šå¾ªç¯æ‰“å°æ¯ä¸ªç±»åˆ«é€šé“\n",
    "for i in range(3):\n",
    "    # å¼ºåˆ¶ç¡®ä¿ä¼ å…¥çš„æ˜¯ (128, 128)\n",
    "    channel_data = probs[i].squeeze() \n",
    "    \n",
    "    im = axes[i+1].imshow(channel_data, cmap=cmaps[i+1])\n",
    "    axes[i+1].set_title(labels[i])\n",
    "    axes[i+1].axis('off')\n",
    "    \n",
    "    # æ‰“å°ç½®ä¿¡åº¦\n",
    "    max_p = np.max(channel_data)\n",
    "    axes[i+1].text(5, 15, f\"Max: {max_p:.2f}\", color='white', \n",
    "                   backgroundcolor='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# å•å…ƒæ ¼ï¼šå®šä¹‰æ··åˆ Loss å‡½æ•° (CE + Dice)\n",
    "# ==========================================\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_hybrid_loss(pred_logits, gt_mask, num_classes=3):\n",
    "    \"\"\"\n",
    "    pred_logits: [B, 3, 128, 128]\n",
    "    gt_mask: [B, 128, 128] (LongTensor)\n",
    "    \"\"\"\n",
    "    # 1. CrossEntropy: å¼ºåˆ¶åƒç´ çº§åˆ†ç±»ç«äº‰\n",
    "    # ç»™èƒŒæ™¯ç±»(0)è¾ƒä½æƒé‡ï¼Œç»™ LV(1) å’Œ Myo(2) æ›´é«˜æƒé‡ï¼Œè§£å†³æ¿€æ´»å¼¥æ•£é—®é¢˜\n",
    "    weights = torch.tensor([0.2, 1.0, 1.2]).to(pred_logits.device)\n",
    "    ce_loss = F.cross_entropy(pred_logits, gt_mask, weight=weights)\n",
    "\n",
    "    # 2. å¤šç±» Dice Loss: ä¼˜åŒ–å½¢çŠ¶è¾¹ç•Œ\n",
    "    pred_probs = F.softmax(pred_logits, dim=1)\n",
    "    target_oh = F.one_hot(gt_mask, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
    "    \n",
    "    # å¿½ç•¥èƒŒæ™¯é€šé“ï¼Œåªç®— LV å’Œ Myo çš„ Dice\n",
    "    dims = (0, 2, 3)\n",
    "    intersection = torch.sum(pred_probs[:, 1:] * target_oh[:, 1:], dims)\n",
    "    cardinality = torch.sum(pred_probs[:, 1:] + target_oh[:, 1:], dims)\n",
    "    dice_loss = 1 - (2. * intersection / (cardinality + 1e-6)).mean()\n",
    "\n",
    "    return ce_loss + dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# å•å…ƒæ ¼ï¼šåˆå§‹åŒ–è®­ç»ƒæ ¸å¿ƒç»„ä»¶\n",
    "# ==========================================\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# 1. å®ä¾‹åŒ–æ··åˆç²¾åº¦ç¼©æ”¾å™¨ (ä¿®å¤ NameError çš„å…³é”®)\n",
    "loss_scaler = GradScaler()\n",
    "\n",
    "# 2. ç¡®ä¿ä¼˜åŒ–å™¨å·²å®šä¹‰\n",
    "# ä½¿ç”¨ AdamWï¼Œå¹¶å°†å­¦ä¹ ç‡è®¾ä¸º 1e-5 ä»¥ä¿è¯å¾®è°ƒçš„ç¨³å®šæ€§\n",
    "optimizer = torch.optim.AdamW(our_model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# 3. è®°å½•è®¾å¤‡ä¿¡æ¯\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… Loss Scaler å·²å°±ç»ªï¼Œå‡†å¤‡åœ¨ {device} ä¸Šè¿›è¡Œ 3 åˆ†ç±»å¾®è°ƒ ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d480c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# å•å…ƒæ ¼ï¼šå¼€å¯ Fine-tuning (å¾®è°ƒ)\n",
    "# ==========================================\n",
    "RUN_EPOCHS = 30 \n",
    "loss_history = []\n",
    "\n",
    "our_model.train()\n",
    "print(f\" æ­£åœ¨è¿›è¡Œå¿ƒè„ 3 åˆ†ç±»å¾®è°ƒè®­ç»ƒ... \")\n",
    "\n",
    "for epoch in range(1, RUN_EPOCHS + 1):\n",
    "    epoch_loss = 0.0\n",
    "    for step, batch_data in enumerate(dl):\n",
    "        # A. æ¬è¿æ•°æ®å¹¶ç”Ÿæˆ BBox æç¤º\n",
    "        images = batch_data[\"image\"].to(device)\n",
    "        gt_masks = batch_data[\"mask\"].squeeze(1).to(device).long()\n",
    "        \n",
    "        # ğŸŸ¢ ä¿®å¤å¼€å§‹ï¼šç°åœºè®¡ç®— BBox å¹¶è£…å…¥è¾“å…¥\n",
    "        batched_input = []\n",
    "        for i in range(len(images)):\n",
    "            \n",
    "            current_mask_np = gt_masks[i].cpu().numpy()\n",
    "            \n",
    "            try:\n",
    "                bbox_result = ff.get_tilted_3d_bbox(current_mask_np, padding=10)\n",
    "                \n",
    "                if bbox_result is not None:\n",
    "                    bbox_list = bbox_result['sam_prompt'] \n",
    "                    \n",
    "                    # ğŸ‘‡ğŸ‘‡ğŸ‘‡ å…³é”®ä¿®æ”¹åœ¨è¿™é‡Œï¼åŠ ä¸Š .unsqueeze(0) ğŸ‘‡ğŸ‘‡ğŸ‘‡\n",
    "                    # ç°åœ¨çš„å½¢çŠ¶å˜æˆ [1, 4]ï¼Œæ¨¡å‹å°±èƒ½çœ‹æ‡‚äº†ï¼\n",
    "                    bbox_tensor = torch.tensor(bbox_list).float().cuda().unsqueeze(0)\n",
    "                else:\n",
    "                    print(f\"Warning: No heart found in image {i}, using full image box.\")\n",
    "                    # è¿™é‡Œçš„å…œåº•æ¡†ä¹Ÿè¦åŠ  unsqueeze(0)\n",
    "                    bbox_tensor = torch.tensor([0, 0, args.img_size, args.img_size]).float().cuda().unsqueeze(0)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"BBox calculation error: {e}\")\n",
    "                bbox_tensor = torch.tensor([0, 0, args.img_size, args.img_size]).float().cuda().unsqueeze(0)\n",
    "\n",
    "            batched_input.append({\n",
    "                'image': images[i],\n",
    "                'original_size': (args.img_size, args.img_size),\n",
    "                'boxes': bbox_tensor \n",
    "            })\n",
    "        # ğŸ”´ ä¿®å¤ç»“æŸ\n",
    "\n",
    "        # B. æ··åˆç²¾åº¦å‰å‘ä¼ æ’­ (AMP)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = our_model(batched_input, multimask_output=True)\n",
    "            # æå– 3 åˆ†ç±» Logits\n",
    "            pred_logits = torch.stack([o['masks'] for o in outputs]).squeeze(1)\n",
    "            loss = calc_hybrid_loss(pred_logits, gt_masks)\n",
    "\n",
    "        # C. ä½¿ç”¨ Scaler æ›´æ–°æ¢¯åº¦ (ä¿®æ­£åçš„æ ‡å‡†æµç¨‹)\n",
    "        # 1. é¦–å…ˆå¯¹ç¼©æ”¾åçš„ loss è¿›è¡Œåå‘ä¼ æ’­\n",
    "        loss_scaler.scale(loss).backward()\n",
    "        \n",
    "        # 2. ç„¶åè®© scaler è§£æ”¾æ¢¯åº¦å¹¶æ‰§è¡Œä¼˜åŒ–å™¨æ­¥è¿›\n",
    "        loss_scaler.step(optimizer)\n",
    "        \n",
    "        # 3. æœ€åæ›´æ–° scaler çš„ç¼©æ”¾å› å­\n",
    "        loss_scaler.update()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(dl)\n",
    "    loss_history.append(avg_loss)\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch [{epoch}/{RUN_EPOCHS}] | å¹³å‡ Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"âœ… æœ¬é˜¶æ®µå¾®è°ƒå®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd3c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®\n",
    "if 'loss_history' not in globals() or len(loss_history) == 0:\n",
    "    print(\"âš ï¸ è¿˜æ²¡æœ‰è®­ç»ƒæ•°æ®ï¼è¯·å…ˆè¿è¡Œä¸Šé¢çš„è®­ç»ƒå¾ªç¯ã€‚\")\n",
    "else:\n",
    "    # 2. ç”Ÿæˆè¡¨æ ¼ (DataFrame)\n",
    "    df_loss = pd.DataFrame({\n",
    "        'Epoch': range(1, len(loss_history) + 1),\n",
    "        'Loss': loss_history\n",
    "    })\n",
    "\n",
    "    # 3. æ‰“å°è¡¨æ ¼ (æ˜¾ç¤ºå‰5è¡Œå’Œå5è¡Œ)\n",
    "    print(\"ğŸ“Š è®­ç»ƒ Loss è¡¨æ ¼ (éƒ¨åˆ†å±•ç¤º):\")\n",
    "    print(df_loss.head(5))\n",
    "    print(\"...\")\n",
    "    print(df_loss.tail(5))\n",
    "\n",
    "    # 4.  ä¿å­˜æˆ CSV æ–‡ä»¶ï¼Œæ–¹ä¾¿ä»¥åçœ‹\n",
    "    #df_loss.to_csv(\"training_loss.csv\", index=False)\n",
    "    #print(f\"\\nâœ… è¡¨æ ¼å·²ä¿å­˜ä¸º: training_loss.csv\")\n",
    "\n",
    "    # 5. ç”» Loss æ›²çº¿å›¾\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df_loss['Epoch'], df_loss['Loss'], marker='o', color='b', label='Training Loss')\n",
    "    \n",
    "    plt.title('Training Loss Curve', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b4ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 1. ç¡®ä¿å‰¥ç¦»æ¢¯åº¦å¹¶è½¬æ¢ä¸ºæ¦‚ç‡\n",
    "# å‡è®¾ final_masks æ¥è‡ªæ¨¡å‹è¾“å‡º\n",
    "# å¦‚æœ final_masks æ˜¯ [1, 3, 128, 128]ï¼Œå…ˆ squeeze(0) å»æ‰ batch ç»´åº¦\n",
    "if final_masks.dim() == 4:\n",
    "    final_masks = final_masks.squeeze(0)\n",
    "\n",
    "probs = torch.sigmoid(final_masks).detach().cpu().numpy()\n",
    "\n",
    "# æ­¤æ—¶ probs åº”è¯¥æ˜¯ (3, 128, 128)\n",
    "print(f\"å¯è§†åŒ–æ•°æ®å½¢çŠ¶ (Probs Shape): {probs.shape}\")\n",
    "\n",
    "# 2. è·å–åº•å›¾\n",
    "img_bg = batch_data[\"image\"].squeeze().cpu().numpy()\n",
    "if img_bg.ndim == 3: # å¤„ç† [3, 1024, 1024]\n",
    "    img_bg = img_bg[0]\n",
    "\n",
    "# 3. ç»˜å›¾é…ç½®\n",
    "labels = ['Background', 'LV Pool', 'Myocardium']\n",
    "cmaps = ['gray', 'Blues', 'Greens', 'Reds']\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# ç¬¬ä¸€å¼ ï¼šåº•å›¾\n",
    "axes[0].imshow(img_bg, cmap='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# åé¢ä¸‰å¼ ï¼šå¾ªç¯æ‰“å°æ¯ä¸ªç±»åˆ«é€šé“\n",
    "for i in range(3):\n",
    "    # å¼ºåˆ¶ç¡®ä¿ä¼ å…¥çš„æ˜¯ (128, 128)\n",
    "    channel_data = probs[i].squeeze() \n",
    "    \n",
    "    im = axes[i+1].imshow(channel_data, cmap=cmaps[i+1])\n",
    "    axes[i+1].set_title(labels[i])\n",
    "    axes[i+1].axis('off')\n",
    "    \n",
    "    # æ‰“å°ç½®ä¿¡åº¦\n",
    "    max_p = np.max(channel_data)\n",
    "    axes[i+1].text(5, 15, f\"Max: {max_p:.2f}\", color='white', \n",
    "                   backgroundcolor='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991483ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\" æ¨¡å‹è¾“å‡ºå½¢çŠ¶ (Final Masks Shape): {final_masks.shape}\")\n",
    "num_output_channels = final_masks.shape[1] if final_masks.dim() == 4 else final_masks.shape[0]\n",
    "print(f\" æ¨¡å‹è¾“å‡ºäº† {num_output_channels} ä¸ªé€šé“\")\n",
    "\n",
    "# 2. æ£€æŸ¥çœŸå€¼ (Ground Truth) åˆ°åº•æœ‰å‡ ä¸ªç±»\n",
    "# ä» DataLoader å†æ‹¿ä¸€ä¸ª batch\n",
    "batch_temp = next(iter(dl))\n",
    "gt_mask_temp = batch_temp[\"mask\"]\n",
    "unique_values = torch.unique(gt_mask_temp).numpy()\n",
    "\n",
    "print(f\" çœŸå®æ ‡ç­¾åŒ…å«çš„å€¼ (Unique Values in GT): {unique_values}\")\n",
    "print(f\" æ•°æ®å®é™…ä¸Šæœ‰ {len(unique_values)} ä¸ªç±»åˆ«\")\n",
    "\n",
    "# 3. æ™ºèƒ½åˆ¤æ–­\n",
    "if len(unique_values) > num_output_channels:\n",
    "    print(\" è­¦å‘Šï¼šæ•°æ®çš„ç±»åˆ«æ•° > æ¨¡å‹è¾“å‡ºé€šé“æ•°ï¼ä½ ä¼šä¸¢æ‰éƒ¨åˆ†ç±»åˆ«ï¼ˆæ¯”å¦‚å³å¿ƒå®¤ï¼‰ï¼\")\n",
    "elif len(unique_values) == 4 and 3 in unique_values:\n",
    "    print(\" å‘ç° 4 ä¸ªç±»åˆ« (0,1,2,3)ï¼å¦‚æœä½ åªæƒ³è¦ LV å’Œ Myoï¼Œè¯·ç¡®è®¤ä»£ç æ˜¯å¦åšäº†æ˜ å°„ã€‚\")\n",
    "    print(\"   é€šå¸¸é¡ºåºæ˜¯: 0-èƒŒæ™¯, 1-å³å¿ƒå®¤, 2-å¿ƒè‚Œ, 3-å·¦å¿ƒå®¤\")\n",
    "else:\n",
    "    print(\" æ•°æ®ä¸æ¨¡å‹é€šé“æ•°çœ‹èµ·æ¥æ˜¯åŒ¹é…çš„ (å«èƒŒæ™¯)ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb11427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# 1. ä»æ•°æ®åŠ è½½å™¨é‡ŒéšæœºæŠ½æŸ¥ä¸€ä¸ª Batch\n",
    "# æ³¨æ„ï¼šæ¯æ¬¡è¿è¡Œè¿™ä¸€è¡Œï¼Œéƒ½ä¼šéšæœºæ¢ä¸€å¼ å›¾\n",
    "try:\n",
    "    batch_check = next(iter(dl))\n",
    "except:\n",
    "    # å¦‚æœ dl å·²ç»è·‘ç©ºäº†ï¼Œé‡æ–°ç”Ÿæˆè¿­ä»£å™¨\n",
    "    batch_check = next(iter(torch.utils.data.DataLoader(dataset_train, batch_size=1, shuffle=True)))\n",
    "\n",
    "# 2. æå–ç¬¬ä¸€å¼ å›¾å’Œå¯¹åº”çš„ Mask\n",
    "img_show = batch_check['image'][0].squeeze().cpu().numpy() # åº•å›¾\n",
    "mask_show = batch_check['mask'][0].squeeze().cpu().numpy() # çœŸå€¼ Mask\n",
    "\n",
    "# 3. å…³é”®æ­¥éª¤ï¼šæ£€æŸ¥ Mask é‡Œçš„æ•°å€¼ï¼\n",
    "unique_vals = np.unique(mask_show)\n",
    "print(f\" ä½ çš„ Ground Truth é‡ŒåŒ…å«è¿™äº›æ•°å€¼: {unique_vals}\")\n",
    "print(f\"ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ ä¸€å…±æœ‰ {len(unique_vals)} ä¸ªç±»åˆ« (å«èƒŒæ™¯)\")\n",
    "\n",
    "# 4. å¯è§†åŒ–é…ç½®\n",
    "colors = ['black', 'lime', 'red', 'cyan', 'yellow']\n",
    "# æ ¹æ®ä½ çš„å®é™…ç±»åˆ«æ•°æˆªå–é¢œè‰²\n",
    "cmap_gt = ListedColormap(colors[:len(unique_vals)]) if len(unique_vals) < 5 else 'jet'\n",
    "\n",
    "# 5. ç”»å›¾å¯¹æ¯”\n",
    "# å‡è®¾ img_show æ˜¯ä» Tensor è½¬è¿‡æ¥çš„ numpy æ•°ç»„\n",
    "# å½¢çŠ¶å¯èƒ½æ˜¯ (3, 128, 128)\n",
    "\n",
    "# å¦‚æœæ˜¯ (3, H, W)ï¼Œæˆ‘ä»¬å°±åªå–ç¬¬ä¸€ä¸ªé€šé“ï¼Œå˜æˆ (H, W)\n",
    "if img_show.ndim == 3 and img_show.shape[0] == 3:\n",
    "    img_show = img_show[0] \n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# å·¦è¾¹ï¼šåŸå§‹ MRI\n",
    "axes[0].imshow(img_show, cmap='gray')\n",
    "axes[0].set_title(\"Original MRI Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# å³è¾¹ï¼š... (ä½ åŸæœ¬çš„ä»£ç )\n",
    "\n",
    "# å³è¾¹ï¼šGround Truth (çœŸå€¼)\n",
    "im = axes[1].imshow(mask_show, cmap=cmap_gt, interpolation='nearest')\n",
    "axes[1].set_title(f\"Ground Truth Mask\\n(Values: {unique_vals})\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# åŠ ä¸ªé¢œè‰²æ¡å¯¹åº”ä¸€ä¸‹\n",
    "cbar = plt.colorbar(im, ax=axes[1], ticks=unique_vals)\n",
    "cbar.ax.set_yticklabels([f\"Class {int(v)}\" for v in unique_vals])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
