{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30136340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('/host/d/Github')\n",
    "import Whole_heart_segmentation_junzhe.functions_collection as ff\n",
    "import Whole_heart_segmentation_junzhe.Data_processing as Data_processing\n",
    "import Whole_heart_segmentation_junzhe.Build_lists.Build_list as Build_list\n",
    "import Whole_heart_segmentation_junzhe.data_loader.random_aug as random_aug\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21de6f2",
   "metadata": {},
   "source": [
    "### step 1: define trial name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de8cb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'trial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0354b4",
   "metadata": {},
   "source": [
    "### step 2: build patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ad3f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all train img files: ['/host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_0.nii.gz'\n",
      " '/host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_1.nii.gz'\n",
      " '/host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_2.nii.gz'\n",
      " '/host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_3.nii.gz'\n",
      " '/host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_4.nii.gz'\n",
      " '/host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_5.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "# change the excel path to your own path\n",
    "patient_list_spreadsheet = os.path.join('/host/d/Github/Whole_heart_segmentation_junzhe/example_data/Patient_list','patient_list.xlsx')\n",
    "build_sheet =  Build_list.Build(patient_list_spreadsheet)\n",
    "# train\n",
    "_, patient_id_list_train, slice_index_list_train, img_file_list_train, seg_file_list_train = build_sheet.__build__(batch_list = [0])  # just as an example, use batch 0 for train\n",
    "print('all train img files:', img_file_list_train)\n",
    "\n",
    "# # define val\n",
    "# _,_,input_file_val, reference_file_val = build_sheet.__build__(batch_list = [1])  # just as an example, use the same batch for val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e48af7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# main function:\n",
    "class Dataset_CMR(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "\n",
    "            image_file_list,\n",
    "            seg_file_list,\n",
    "\n",
    "            center_crop_according_to_which_class  = [1], #default: crop according to class 1 (LV)\n",
    "\n",
    "            image_shape = None, # [x,y], default = [128,128]\n",
    "            shuffle = None,\n",
    "            image_normalization = True,\n",
    "            augment = None,\n",
    "            augment_frequency = 0.5, # how often do we do augmentation\n",
    "            ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.image_file_list = image_file_list\n",
    "        self.seg_file_list = seg_file_list\n",
    "        self.center_crop_according_to_which_class = center_crop_according_to_which_class\n",
    "        self.image_shape = image_shape\n",
    "        self.shuffle = shuffle\n",
    "        self.image_normalization = image_normalization\n",
    "        self.augment = augment\n",
    "        self.augment_frequency = augment_frequency\n",
    "\n",
    "        # how many cases we have in this dataset?\n",
    "        self.num_files = len(self.image_file_list)\n",
    "\n",
    "        # the following two should be run at the beginning of each epoch\n",
    "        # 1. get index array\n",
    "        self.index_array = self.generate_index_array()\n",
    "\n",
    "        # 2. some parameters\n",
    "        self.current_image_file = None\n",
    "        self.current_image_data = None \n",
    "        self.current_seg_file = None\n",
    "        self.current_seg_data = None\n",
    "\n",
    "    # function: how many sample do we have in this dataset? \n",
    "    def __len__(self):\n",
    "        return self.num_files\n",
    "        \n",
    "    # function: we need to generate an index array for dataloader, it's a list, each element is [file_index, slice_index]\n",
    "    def generate_index_array(self):\n",
    "        np.random.seed()\n",
    "                \n",
    "        if self.shuffle == True:\n",
    "            file_index_list = np.random.permutation(self.num_files)\n",
    "        else:\n",
    "            file_index_list = np.arange(self.num_files)\n",
    "\n",
    "        index_array = file_index_list.tolist()  # each element is file index now\n",
    "\n",
    "        return index_array\n",
    "    \n",
    "    # function: \n",
    "    def load_file(self, filename, segmentation_load = False):\n",
    "        ii = nb.load(filename).get_fdata()\n",
    "\n",
    "        if segmentation_load is True:\n",
    "            ii = np.round(ii).astype(int)\n",
    "    \n",
    "        return ii\n",
    "    \n",
    "\n",
    "    # function: get each item using the index [file_index]\n",
    "    def __getitem__(self, index):\n",
    "        f = self.index_array[index]\n",
    "        image_filename = self.image_file_list[f]\n",
    "        seg_filename = self.seg_file_list[f]\n",
    "        print('loading image file:', image_filename, ' seg file:', seg_filename)\n",
    "\n",
    "        # check if manual seg exists\n",
    "        if os.path.isfile(seg_filename) is False:\n",
    "            self.have_manual_seg = False\n",
    "        else:\n",
    "            self.have_manual_seg = True\n",
    "            \n",
    "        # if it's a new case, then do the data loading; if it's not, then just use the current data\n",
    "        if image_filename != self.current_image_file or seg_filename != self.current_seg_file:\n",
    "            image_loaded = self.load_file(image_filename, segmentation_load = False) \n",
    "\n",
    "            if self.have_manual_seg is True:\n",
    "                seg_loaded = self.load_file(seg_filename, segmentation_load = True) \n",
    "            else:\n",
    "                seg_loaded = np.zeros(image_loaded.shape, dtype = np.int)\n",
    "\n",
    "\n",
    "        # center crop\n",
    "        if self.have_manual_seg is True:\n",
    "            # find centroid based on the segmenation class 1\n",
    "            _,_, self.centroid = Data_processing.center_crop( image_loaded, seg_loaded, self.image_shape, according_to_which_class = self.center_crop_according_to_which_class , centroid = None)\n",
    "\n",
    "        elif self.have_manual_seg is False:\n",
    "            # center is the image center\n",
    "            self.centroid = [image_loaded.shape[0]//2, image_loaded.shape[1]//2]\n",
    "\n",
    "         # random crop (randomly shift the centroid)\n",
    "        if self.augment == True and np.random.uniform(0,1)  < self.augment_frequency:\n",
    "            random_centriod_shift_x = np.random.randint(-5,5)\n",
    "            random_centriod_shift_y = np.random.randint(-5,5)\n",
    "            centroid_used_for_crop = [self.centroid[0] + random_centriod_shift_x, self.centroid[1] + random_centriod_shift_y]\n",
    "        else:\n",
    "            centroid_used_for_crop = self.centroid\n",
    "                \n",
    "        # crop this 2D case\n",
    "        image_loaded = image_loaded[centroid_used_for_crop[0] - self.image_shape[0]//2 : centroid_used_for_crop[0] + self.image_shape[0]//2,\n",
    "                                        centroid_used_for_crop[1] - self.image_shape[1]//2 : centroid_used_for_crop[1] + self.image_shape[1]//2 ]\n",
    "        seg_loaded = seg_loaded[centroid_used_for_crop[0] - self.image_shape[0]//2 : centroid_used_for_crop[0] + self.image_shape[0]//2,\n",
    "                                        centroid_used_for_crop[1] - self.image_shape[1]//2 : centroid_used_for_crop[1] + self.image_shape[1]//2 ]\n",
    "        \n",
    "        # temporarily save our data\n",
    "        self.current_image_file = image_filename\n",
    "        self.current_image_data = np.copy(image_loaded)  \n",
    "        self.current_seg_file = seg_filename\n",
    "        self.current_seg_data = np.copy(seg_loaded)\n",
    "\n",
    "        # augmentation\n",
    "        original_image = np.copy(image_loaded)\n",
    "        original_seg = np.copy(seg_loaded)\n",
    "      \n",
    "        ######## do augmentation\n",
    "        processed_seg = np.copy(original_seg)\n",
    "        # (0) add noise\n",
    "        if self.augment == True and np.random.uniform(0,1)  < self.augment_frequency:\n",
    "            standard_deviation = 5\n",
    "            processed_image = original_image + np.random.normal(0,standard_deviation,original_image.shape)\n",
    "            # turn the image pixel range to [0,255]\n",
    "            processed_image = Data_processing.turn_image_range_into_0_255(processed_image)\n",
    "        else:\n",
    "            processed_image = Data_processing.turn_image_range_into_0_255(original_image)\n",
    "       \n",
    "        # (1) do brightness\n",
    "        if self.augment == True and np.random.uniform(0,1)  < self.augment_frequency:\n",
    "            processed_image,v = random_aug.random_brightness(processed_image, v = None)\n",
    "    \n",
    "        # (2) do contrast\n",
    "        if self.augment == True and np.random.uniform(0,1)  < self.augment_frequency:\n",
    "            processed_image, v = random_aug.random_contrast(processed_image, v = None)\n",
    "\n",
    "        # (3) do sharpness\n",
    "        if self.augment == True and np.random.uniform(0,1)  < self.augment_frequency:\n",
    "            processed_image, v = random_aug.random_sharpness(processed_image, v = None)\n",
    "            \n",
    "        # (4) do flip\n",
    "        if self.augment == True and np.random.uniform(0,1)  < self.augment_frequency:\n",
    "            # doing this can make sure the flip is the same for image and seg\n",
    "            a, selected_option = random_aug.random_flip(processed_image)\n",
    "            b,_ = random_aug.random_flip(processed_seg, selected_option)\n",
    "            processed_image = np.copy(a)\n",
    "            processed_seg = np.copy(b)\n",
    "\n",
    "        # (5) do rotate\n",
    "        if self.augment == True and np.random.uniform(0,1)  < self.augment_frequency:\n",
    "            processed_image, z_rotate_degree = random_aug.random_rotate(processed_image, order = 1, z_rotate_range = [-10,10])\n",
    "            processed_seg,_ = random_aug.random_rotate(processed_seg, z_rotate_degree, fill_val = 0, order = 0)\n",
    "\n",
    "        # (6) do translate\n",
    "        if self.augment == True and np.random.uniform(0,1)  < self.augment_frequency:\n",
    "            processed_image, x_translate, y_translate = random_aug.random_translate(processed_image, translate_range = [-10,10])\n",
    "            processed_seg,_ ,_= random_aug.random_translate(processed_seg, x_translate, y_translate)\n",
    "\n",
    "        # add normalization\n",
    "        if self.image_normalization is True:\n",
    "            processed_image = Data_processing.normalize_image(processed_image,inverse = False) \n",
    "\n",
    "        print('after augmentation, image min:', np.min(processed_image), ' max:', np.max(processed_image))\n",
    "\n",
    "        # put into torch tensor\n",
    "        processed_image = torch.from_numpy(processed_image).float().unsqueeze(0)  # add channel dimension\n",
    "        processed_seg = torch.from_numpy(processed_seg).float().unsqueeze(0)  # add channel dimension\n",
    "\n",
    "\n",
    "        return processed_image, processed_seg, original_image, original_seg\n",
    "          \n",
    "        \n",
    "     \n",
    "        \n",
    "    \n",
    "    # function: at the end of each epoch, we need to reset the index array\n",
    "    def on_epoch_end(self):\n",
    "        print('now run on_epoch_end function')\n",
    "        self.index_array = self.generate_index_array()\n",
    "\n",
    "        self.current_image_file = None\n",
    "        self.current_image_data = None \n",
    "        self.current_seg_file = None\n",
    "        self.current_seg_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4def2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define this generator\n",
    "generator_train = Dataset_CMR(\n",
    "    image_file_list = img_file_list_train,\n",
    "    \n",
    "    seg_file_list = seg_file_list_train,\n",
    "\n",
    "    image_shape = [128,128],\n",
    "    center_crop_according_to_which_class  = [1], #default: crop according to class 1 (LV)\n",
    "\n",
    "    shuffle = True,\n",
    "    image_normalization = True,\n",
    "    augment = True,\n",
    "    augment_frequency = 0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0108c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = generator_train\n",
    "dl = DataLoader(ds, batch_size = 3, shuffle = False, pin_memory = True, num_workers = 0)# cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc21e9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_3.nii.gz  seg file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/seg/slice_3.nii.gz\n",
      "after augmentation, image min: 0.0  max: 1.0\n",
      "loading image file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_1.nii.gz  seg file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/seg/slice_1.nii.gz\n",
      "after augmentation, image min: 0.0  max: 1.0\n",
      "loading image file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_5.nii.gz  seg file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/seg/slice_5.nii.gz\n",
      "after augmentation, image min: 0.0  max: 1.0\n",
      "shape of images: torch.Size([3, 1, 128, 128])  shape of segs: torch.Size([3, 1, 128, 128])\n",
      "loading image file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_0.nii.gz  seg file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/seg/slice_0.nii.gz\n",
      "after augmentation, image min: 0.0  max: 1.0\n",
      "loading image file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_4.nii.gz  seg file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/seg/slice_4.nii.gz\n",
      "after augmentation, image min: 0.0  max: 1.0\n",
      "loading image file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/img/slice_2.nii.gz  seg file: /host/d/GitHub/Whole_heart_segmentation_junzhe/example_data/data/ID_0002/seg/slice_2.nii.gz\n",
      "after augmentation, image min: 0.0  max: 1.0\n",
      "shape of images: torch.Size([3, 1, 128, 128])  shape of segs: torch.Size([3, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for batch in dl:\n",
    "    images, segs, _,_ = batch\n",
    "    \n",
    "    # put into GPU if needed\n",
    "    images = images.to(device)\n",
    "    segs = segs.to(device)\n",
    "\n",
    "    print('shape of images:', images.shape, ' shape of segs:', segs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ce1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
